{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fh\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myloss(theta,i,show=False):\n",
    "    beta = torch.ones([m, n], dtype=torch.float64)*(2**i)\n",
    "    A = torch.sigmoid(beta*theta)\n",
    "    M = torch.matmul(torch.t(A), A)\n",
    "    if (show):\n",
    "        print(A)\n",
    "    return torch.norm(M-I) #+ lam*torch.norm(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311],\n",
      "        [0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311],\n",
      "        [0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311],\n",
      "        ...,\n",
      "        [0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311],\n",
      "        [0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311],\n",
      "        [0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor(1602.3708, dtype=torch.float64, grad_fn=<NormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "m = 30\n",
    "n = 100\n",
    "I = torch.eye(n, dtype=torch.float64)\n",
    "\n",
    "# beta = torch.ones([m, n], dtype=torch.float64, requires_grad=True)\n",
    "x = torch.ones([m, n], dtype=torch.float64, requires_grad=True)\n",
    "# temp = torch.norm(x)\n",
    "# x.data = x.data/temp\n",
    "\n",
    "y = myloss(x,0,True)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 1  epoch: 1000  loss: 735.4371256536828\n",
      "beta: 1  epoch: 2000  loss: 735.437123134272\n",
      "beta: 1  epoch: 3000  loss: 735.4371229537431\n",
      "beta: 1  epoch: 4000  loss: 735.4371229334753\n",
      "beta: 1  epoch: 5000  loss: 735.4371229308604\n",
      "beta: 1  epoch: 6000  loss: 735.4371229304274\n",
      "beta: 1  epoch: 7000  loss: 735.4371229304143\n",
      "beta: 1  epoch: 8000  loss: 735.4371229304182\n",
      "beta: 1  epoch: 9000  loss: 735.4371229303973\n",
      "beta: 1  epoch: 10000  loss: 735.4371229304669\n",
      "beta: 1  epoch: 11000  loss: 735.4371229303578\n",
      "beta: 1  epoch: 12000  loss: 735.4371229304494\n",
      "beta: 1  epoch: 13000  loss: 735.437122930364\n",
      "beta: 1  epoch: 14000  loss: 735.4371229303924\n",
      "beta: 1  epoch: 15000  loss: 735.4371229304194\n",
      "beta: 1  epoch: 16000  loss: 735.4371229303774\n",
      "beta: 1  epoch: 17000  loss: 735.4371229304386\n",
      "beta: 1  epoch: 18000  loss: 735.4371229303674\n",
      "beta: 1  epoch: 19000  loss: 735.4371229303599\n",
      "beta: 1  epoch: 20000  loss: 735.4371229303754\n",
      "beta: 1  epoch: 21000  loss: 735.4371229303963\n",
      "beta: 1  epoch: 22000  loss: 735.4371229303986\n",
      "beta: 1  epoch: 23000  loss: 735.4371229303988\n",
      "beta: 1  epoch: 24000  loss: 735.437122930399\n",
      "beta: 1  epoch: 25000  loss: 735.437122930399\n",
      "beta: 1  epoch: 26000  loss: 735.437122930399\n",
      "beta: 1  epoch: 27000  loss: 735.437122930399\n",
      "beta: 1  epoch: 28000  loss: 735.437122930399\n",
      "beta: 1  epoch: 29000  loss: 735.437122930399\n",
      "beta: 1  epoch: 30000  loss: 735.437122930399\n",
      "beta: 1  epoch: 31000  loss: 735.437122930399\n",
      "beta: 1  epoch: 32000  loss: 735.437122930399\n",
      "beta: 1  epoch: 33000  loss: 735.437122930399\n",
      "beta: 1  epoch: 34000  loss: 735.437122930399\n",
      "beta: 1  epoch: 35000  loss: 735.437122930399\n",
      "beta: 1  epoch: 36000  loss: 735.437122930399\n",
      "beta: 1  epoch: 37000  loss: 735.437122930399\n",
      "beta: 1  epoch: 38000  loss: 735.437122930399\n",
      "beta: 1  epoch: 39000  loss: 735.437122930399\n",
      "beta: 1  epoch: 40000  loss: 735.437122930399\n",
      "beta: 1  epoch: 41000  loss: 735.437122930399\n",
      "beta: 1  epoch: 42000  loss: 735.437122930399\n",
      "beta: 1  epoch: 43000  loss: 735.437122930399\n",
      "beta: 1  epoch: 44000  loss: 735.437122930399\n",
      "beta: 1  epoch: 45000  loss: 735.437122930399\n",
      "beta: 1  epoch: 46000  loss: 735.437122930399\n",
      "beta: 1  epoch: 47000  loss: 735.437122930399\n",
      "beta: 1  epoch: 48000  loss: 735.437122930399\n",
      "beta: 1  epoch: 49000  loss: 735.437122930399\n",
      "beta: 1  epoch: 50000  loss: 735.437122930399\n",
      "beta: 1  epoch: 51000  loss: 735.437122930399\n",
      "beta: 1  epoch: 52000  loss: 735.437122930399\n",
      "beta: 1  epoch: 53000  loss: 735.437122930399\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# x = torch.tensor(.0, requires_grad=True)\n",
    "# y = (x-2)**2\n",
    "\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.SGD([x], lr=0.0001)\n",
    "\n",
    "\n",
    "# initilizae\n",
    "# print(x,y)\n",
    "for j in range(10):\n",
    "#     if (j!=0):\n",
    "#         x.data = x.data/2\n",
    "    for i in range(100000):\n",
    "        optimizer.zero_grad()\n",
    "        y = myloss(x,0)\n",
    "        y.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        temp = torch.norm(x)\n",
    "        x.data = x.data/temp\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print('beta:',2**j,' epoch:',i + 1,' loss:',y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        ...,\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003]],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor(10.0000, dtype=torch.float64, grad_fn=<NormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(myloss(x,1,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
